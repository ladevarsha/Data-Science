{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c57ceab-625f-4f0c-a126-0a6acee7342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Ans-\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Define the column transformer for numerical and categorical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Use a feature selection method to identify important features\n",
    "selector = SelectFromModel(RandomForestClassifier())\n",
    "\n",
    "# Define the final pipeline with preprocessor, feature selector, and classifier\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy of the model on the test data\n",
    "accuracy = rf_pipeline.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "In this pipeline, we first define a ColumnTransformer to handle the numerical and categorical features separately. The numerical features are imputed using the mean of the column values and then scaled using standardization. The categorical features are imputed using the most frequent value of the column and then one-hot encoded.\n",
    "\n",
    "Next, we use a SelectFromModel feature selection method with a RandomForestClassifier to identify important features.\n",
    "\n",
    "Finally, we define the final pipeline with the preprocessor, feature selector, and a RandomForestClassifier as the final classifier.\n",
    "\n",
    "We train the model on the training data and evaluate its accuracy on the test data.\n",
    "\n",
    "To improve the pipeline, we could try different feature selection methods or hyperparameters for the classifier. We could also try different imputation strategies for missing values or different scaling methods for the numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87b286a-04e0-4b6c-959f-f9e643941b4d",
   "metadata": {},
   "source": [
    "Q.2 Ans-\n",
    "       \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Create pipelines for the individual classifiers\n",
    "rf_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "lr_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder()),\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Create the voting classifier\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('rf', rf_pipeline), ('lr', lr_pipeline)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Train the pipeline on the data\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy on the test set\n",
    "accuracy = voting_classifier.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "In this example, we create separate pipelines for the Random Forest Classifier and the Logistic Regression Classifier, each including any necessary preprocessing steps such as imputation, scaling, and one-hot encoding. We then create a Voting Classifier that combines the predictions of these two classifiers using a soft voting strategy, which takes the predicted probabilities and averages them to make a final prediction.\n",
    "\n",
    "We train the entire pipeline on the training data and evaluate its accuracy on the test set. The final accuracy score can be used to assess the performance of the ensemble classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
