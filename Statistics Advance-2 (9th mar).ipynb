{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c4d239-8097-434d-9cef-a7f53d1a11d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
    "an example.\n",
    "Ans-\n",
    "    The Probability Mass Function (PMF) and Probability Density Function (PDF) are both mathematical functions that describe the probability distribution of a random variable.\n",
    "\n",
    "A PMF is a function that maps each possible value of a discrete random variable to its probability of occurrence. It gives the probability of a discrete random variable taking on a specific value. For example, consider the roll of a fair six-sided die. The PMF for this random variable assigns a probability of 1/6 to each possible outcome of rolling the die (i.e., the values 1, 2, 3, 4, 5, or 6). The PMF is defined as:\n",
    "\n",
    "    P(X = x) = 1/6, for x = 1, 2, 3, 4, 5, 6\n",
    "    \n",
    "Here, X is the random variable representing the outcome of a roll of the die, and x is one of the possible values that X can take.\n",
    "\n",
    "On the other hand, a PDF is a function that describes the probability distribution of a continuous random variable. It gives the probability density of a continuous random variable taking on a specific value. For example, consider the normal distribution with mean μ and standard deviation σ. The PDF for this random variable is given by the following formula:\n",
    "    \n",
    "      f(x) = (1 / (σ * √(2π))) * exp(-((x - μ)^2) / (2 * σ^2))\n",
    "        \n",
    "This formula gives the probability density of the normal distribution at any point x. Note that the PDF does not give the probability of the random variable taking on a specific value (since the probability of a continuous random variable taking on any specific value is zero). Rather, it gives the relative likelihood of the random variable being in a particular range of values.\n",
    "\n",
    "In summary, the PMF and PDF are both functions that describe the probability distribution of a random variable, but the PMF is used for discrete random variables, while the PDF is used for continuous random variables. The PMF gives the probability of the random variable taking on a specific value, while the PDF gives the probability density of the random variable at any point.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166660c5-e176-432a-b726-d03eb3e14620",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?\n",
    "Ans-\n",
    "   The Cumulative Density Function (CDF) is a mathematical function that describes the probability that a random variable takes on a value less than or equal to a certain point. It gives the cumulative probability of the random variable up to a certain point. In other words, the CDF is the integral of the PDF (or the sum of the PMF, in the discrete case) up to a certain point.\n",
    "\n",
    "For example, let's consider the roll of a fair six-sided die. The PMF for this random variable is given by:\n",
    "\n",
    "       P(X = x) = 1/6, for x = 1, 2, 3, 4, 5, 6\n",
    "    \n",
    "The CDF for this random variable is given by:\n",
    "    \n",
    "    F(x) = P(X ≤ x) = ∑ P(X = i), for i = 1, 2, ..., x\n",
    "\n",
    "This formula gives the probability that the value of the random variable is less than or equal to a certain value x. For instance, the probability of rolling a number less than or equal to 3 on the die is:\n",
    "    \n",
    "    F(3) = P(X ≤ 3) = P(X = 1) + P(X = 2) + P(X = 3) = 1/6 + 1/6 + 1/6 = 1/2\n",
    "    \n",
    "Therefore, the CDF gives us information about the probability distribution of the random variable and allows us to calculate probabilities for specific events or ranges of values.\n",
    "\n",
    "The CDF is useful for several reasons. First, it provides a summary of the entire probability distribution of the random variable, not just at a specific point or range of values. Second, it allows us to calculate probabilities for any interval of values, not just for specific values like the PMF or PDF. Finally, the CDF can be used to calculate other useful measures of the probability distribution, such as the median or quartiles.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03be7932-eb55-4390-9117-a9b871ee1326",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution.\n",
    "Ans-\n",
    "    The normal distribution, also known as the Gaussian distribution, is one of the most commonly used probability distributions in statistics. It is a continuous distribution that is symmetric around its mean, with the majority of the data concentrated around the mean and decreasing towards the tails. Some examples of situations where the normal distribution might be used as a model are:\n",
    "\n",
    "1.Heights or weights of people in a population: These measurements are often normally distributed, with most people being around the average height or weight and fewer people being either very tall or very short, or very heavy or very light.\n",
    "\n",
    "2.Test scores: If a test is designed such that the scores are distributed normally, then the average score will be the mean of the distribution, and the standard deviation will determine how spread out the scores are.\n",
    "\n",
    "3.Errors in measurements: Any measurement is subject to errors, and if these errors are distributed normally, then the normal distribution can be used to model the errors.\n",
    "\n",
    "The normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). The mean is the center of the distribution, and determines the location of the peak. The standard deviation is a measure of the spread of the distribution, with larger values of σ resulting in flatter and more spread-out distributions, and smaller values of σ resulting in taller and more concentrated distributions.\n",
    "\n",
    "The shape of the normal distribution is also affected by the value of μ and σ. If μ is shifted to the right or left, then the distribution will be shifted accordingly. If σ is increased, the distribution will become flatter and more spread out. If σ is decreased, the distribution will become taller and more concentrated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ec9c72-0762-41b9-aa92-3e412a94d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
    "Distribution.\n",
    "Ans-\n",
    "   \n",
    "    The normal distribution is an important concept in statistics and data analysis. It is used to model a wide range of phenomena in different fields, and its properties make it a useful tool for various applications. Some of the main reasons why the normal distribution is important are:\n",
    "\n",
    "1.Central Limit Theorem: One of the most important applications of the normal distribution is in the Central Limit Theorem, which states that the sample means of a large number of independent and identically distributed random variables will be approximately normally distributed, regardless of the underlying distribution. This theorem is important because it allows us to use normal distribution-based techniques to analyze a wide range of data.\n",
    "\n",
    "2.Data analysis and modeling: The normal distribution is commonly used to model a wide range of phenomena in different fields such as finance, physics, engineering, and social sciences. It provides a convenient way to describe the variability and distribution of data, and helps to identify patterns and trends.\n",
    "\n",
    "3.Hypothesis testing: The normal distribution is a key element in many statistical tests such as t-tests, ANOVA, and regression analysis. These tests rely on the assumption that the data is normally distributed, and they provide a way to test hypotheses and draw conclusions about population parameters based on the sample data.\n",
    "\n",
    "   Some real-life examples of normal distribution are:\n",
    "\n",
    "1.Heights of a population: The heights of a population tend to follow a normal distribution with a mean around 5 feet 7 inches (170 cm) for men and 5 feet 4 inches (163 cm) for women, and a standard deviation of about 3 inches (8 cm).\n",
    "\n",
    "2.IQ scores: IQ scores are standardized to have a normal distribution with a mean of 100 and a standard deviation of 15. This means that most people have an IQ score between 85 and 115.\n",
    "\n",
    "3.Body temperature: Body temperature in healthy individuals tends to follow a normal distribution with a mean of 98.6°F (37°C) and a standard deviation of 0.5°F (0.3°C).\n",
    "\n",
    "4.Stock prices: Stock prices can be modeled using a log-normal distribution, which is a transformation of the normal distribution. This allows us to estimate the probability of a particular stock price occurring, and to calculate various risk measures such as value at risk.\n",
    "\n",
    "5.Exam scores: Exam scores in a class tend to follow a normal distribution, which allows us to estimate the average score and the variability of the scores, and to identify students who may need additional help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb90a47-598c-4fca-b7ec-9d3897eec7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "Distribution and Binomial Distribution?\n",
    "Ans-\n",
    "    The Bernoulli distribution is a probability distribution that models the outcomes of a single trial of a binary experiment (an experiment with two possible outcomes). The distribution has a probability parameter, usually denoted by p, which represents the probability of success in the trial (the probability of getting the favorable outcome).\n",
    "\n",
    "For example, consider the experiment of flipping a fair coin. The Bernoulli distribution can be used to model the outcome of a single flip, where success can be defined as getting heads (with probability p=0.5) and failure can be defined as getting tails (with probability 1-p=0.5). In this case, the Bernoulli distribution has only two possible outcomes: 1 for success and 0 for failure.\n",
    "\n",
    "The main difference between the Bernoulli distribution and the binomial distribution is that the Bernoulli distribution models the outcome of a single trial, while the binomial distribution models the number of successes in a fixed number of independent and identically distributed Bernoulli trials.\n",
    "\n",
    "For example, consider the experiment of flipping a fair coin 10 times. The binomial distribution can be used to model the number of times heads appears, where each trial is a Bernoulli trial with probability of success p=0.5. In this case, the binomial distribution has 11 possible outcomes (0 to 10) and its probability mass function gives the probabilities of each outcome.\n",
    "\n",
    "To summarize, the Bernoulli distribution is a special case of the binomial distribution where there is only one trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c74982b-43d9-4bba-b752-edc6c02717e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "than 60? Use the appropriate formula and show your calculations.\n",
    "Ans-\n",
    "    To calculate the probability that a randomly selected observation from a normally distributed dataset with a mean of 50 and a standard deviation of 10 will be greater than 60, we need to use the standard normal distribution.\n",
    "\n",
    "First, we need to standardize the value of 60 using the formula:\n",
    "\n",
    "     z = (x - μ) / σ\n",
    "\n",
    "where x is the value of 60, μ is the mean of 50, and σ is the standard deviation of 10.\n",
    "\n",
    "     z = (60 - 50) / 10 = 1\n",
    "\n",
    "Next, we need to find the probability of a standard normal distribution being greater than 1. This can be done by looking up the area under the standard normal curve to the right of z = 1. We can use a table or a calculator to find this probability. Using a standard normal table, we find that the area to the right of z = 1 is approximately 0.1587.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from the given normally distributed dataset will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469cb7d5-9366-45d8-818f-6c80e33c8847",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7: Explain uniform Distribution with an example.\n",
    "Ans-\n",
    "    Uniform distribution is a probability distribution where each possible value of a variable has an equal chance of occurring. In other words, the probability density function of a uniform distribution is constant over a certain range and zero outside that range.\n",
    "\n",
    "For example, consider the experiment of rolling a fair six-sided die. The outcome of the experiment can be modeled using a uniform distribution since each of the six possible outcomes (1, 2, 3, 4, 5, or 6) has an equal chance of occurring. In this case, the probability density function of the uniform distribution is:\n",
    "\n",
    "      f(x) = 1/6 for x = 1, 2, 3, 4, 5, or 6\n",
    "\n",
    "This means that the probability of getting any of the six possible outcomes is the same, and the probability of getting any value outside this range is zero.\n",
    "\n",
    "Uniform distribution can also be used to model situations where there is no preference for any value within a given range. For example, the distribution of the arrival time of a bus at a stop during a certain period of time could be modeled using a uniform distribution, where any minute within that period has an equal chance of the bus arriving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe76dc55-47ae-4bb8-b65b-58889c30cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8: What is the z score? State the importance of the z score.\n",
    "Ans-\n",
    "    The z-score, also known as the standard score, is a measure of how many standard deviations an observation or data point is away from the mean of a dataset. It is calculated by subtracting the mean from the observation and dividing the result by the standard deviation.\n",
    "\n",
    "The formula for calculating the z-score is:\n",
    "\n",
    "      z = (x - μ) / σ\n",
    "\n",
    "where x is the observation, μ is the mean of the dataset, and σ is the standard deviation of the dataset.\n",
    "\n",
    "The importance of the z-score lies in its ability to help standardize data across different scales and distributions. By transforming the data into z-scores, we can compare observations from different datasets that have different units and scales. Z-scores are also used to identify outliers and to calculate probabilities and percentiles based on standard normal distribution tables.\n",
    "\n",
    "For example, if we have a dataset of exam scores with a mean of 75 and a standard deviation of 10, we can use the z-score to find the proportion of students who scored above a certain value. If we want to find the proportion of students who scored above 85, we can calculate the z-score as:\n",
    "\n",
    "     z = (85 - 75) / 10 = 1\n",
    "\n",
    "We can then use a standard normal distribution table to find the proportion of students with a z-score greater than 1, which is approximately 0.1587. This means that about 15.87% of students scored above 85 on the exam.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0507033-60be-4211-af62-94783bc4bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem.\n",
    "Ans-\n",
    "   The Central Limit Theorem (CLT) states that as the sample size of a random sample from any population increases, the distribution of the sample means approaches a normal distribution, regardless of the shape of the original population distribution. In other words, the distribution of the means of repeated samples taken from a population will approximate a normal distribution, regardless of the underlying distribution of the population.\n",
    "\n",
    "The significance of the Central Limit Theorem is that it provides a useful tool for statistical inference, allowing us to make inferences about population parameters from sample statistics. It allows us to use the normal distribution as an approximation for the sampling distribution of the sample mean, which enables us to make probabilistic statements about the population mean and construct confidence intervals and perform hypothesis testing.\n",
    "\n",
    "For example, let's say we want to estimate the mean height of all individuals in a population. We can take a random sample of 100 individuals and calculate the sample mean height. Using the Central Limit Theorem, we can assume that the distribution of the sample means will be approximately normal, regardless of the shape of the population distribution. This enables us to make probabilistic statements about the population mean height, such as calculating a confidence interval or testing a hypothesis about the population mean height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f27638f-c86f-4480-aa08-57b20583891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10: State the assumptions of the Central Limit Theorem.\n",
    "Ans-\n",
    "   The Central Limit Theorem (CLT) has some assumptions that need to be satisfied for it to be applicable:\n",
    "\n",
    "1.The samples are drawn randomly and independently from the population.\n",
    "2.The population has a finite mean and a finite variance.\n",
    "3.The sample size is sufficiently large. While there is no strict rule on what constitutes a large sample size, a commonly used rule of thumb is that the sample size should be greater than or equal to 30.\n",
    "4.The samples are identically distributed, meaning that they come from the same population.\n",
    "\n",
    "If these assumptions are satisfied, the Central Limit Theorem can be used to make inferences about population parameters from sample statistics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
